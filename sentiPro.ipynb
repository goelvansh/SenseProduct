{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vdRZFijK8xte"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeiKuIut8jkV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import openai\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Amazon product reviews dataset\n"
      ],
      "metadata": {
        "id": "5WmaQW6c83HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df = pd.read_json('reviews.json', lines=True)\n",
        "qa_df = pd.read_json('qa.json', lines=True)\n",
        "\n",
        "# Combine the two datasets based on 'asin' (product ID)\n",
        "merged_df = pd.merge(reviews_df, qa_df, on='asin', how='left')"
      ],
      "metadata": {
        "id": "JtcS-CeO887g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n"
      ],
      "metadata": {
        "id": "_TC3m4zc9F_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates to avoid multiple reviews from the same user for the same product\n",
        "merged_df.drop_duplicates(subset=['reviewerID', 'asin', 'reviewTime', 'reviewText'], inplace=True)\n",
        "\n",
        "# Fill missing values with empty string\n",
        "merged_df.fillna('', inplace=True)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def text_preprocessing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<[^>]+>', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "merged_df['CleanedText'] = merged_df['reviewText'].apply(text_preprocessing)"
      ],
      "metadata": {
        "id": "GvZble-o9IrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "Ge481qXv9SBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of product ratings\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(merged_df['overall'])\n",
        "plt.title('Distribution of Product Ratings')\n",
        "plt.xlabel('Ratings')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# Distribution of review lengths\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(merged_df['CleanedText'].apply(len), bins=30)\n",
        "plt.title('Distribution of Review Lengths')\n",
        "plt.xlabel('Review Length')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(merged_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4PDJWtMb9VX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment Analysis using RoBERTa Model"
      ],
      "metadata": {
        "id": "6U-bHPxm9ZQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "\n",
        "# Function to get sentiment scores using the RoBERTa model\n",
        "def get_sentiment_scores(text):\n",
        "    encoded_text = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "    output = model(**encoded_text)\n",
        "    scores = output.logits[0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'roberta_neg': scores[0],\n",
        "        'roberta_neu': scores[1],\n",
        "        'roberta_pos': scores[2]\n",
        "    }\n",
        "    return scores_dict\n",
        "\n",
        "# Compute sentiment scores for each review and store them in a DataFrame\n",
        "res = {}\n",
        "for i, row in tqdm(merged_df.iterrows(), total=len(merged_df)):\n",
        "    try:\n",
        "        text = row['CleanedText']\n",
        "        myid = row['reviewerID']\n",
        "        sentiment_scores = get_sentiment_scores(text)\n",
        "        res[myid] = sentiment_scores\n",
        "    except RuntimeError:\n",
        "        print(f'Broke for id {myid}')\n",
        "\n",
        "results_df = pd.DataFrame(res).T\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'reviewerID'})\n",
        "merged_df = pd.merge(merged_df, results_df, on='reviewerID', how='left')"
      ],
      "metadata": {
        "id": "pUOUhbPl9cJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collaborative Filtering using SVD++"
      ],
      "metadata": {
        "id": "o5LqC2Mb9hiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only relevant columns for collaborative filtering\n",
        "collab_df = merged_df[['reviewerID', 'asin', 'overall']]\n",
        "\n",
        "# Define the rating scale (useful for Surprise library)\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Create the Surprise dataset\n",
        "data = Dataset.load_from_df(collab_df, reader)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the collaborative filtering model using SVD (Singular Value Decomposition)\n",
        "collab_model = SVD()\n",
        "\n",
        "# Train the collaborative filtering model on the training set\n",
        "collab_model.fit(trainset)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = collab_model.test(testset)"
      ],
      "metadata": {
        "id": "stAOiBy19kvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Content-Based Filtering using NLP-based Recommendations"
      ],
      "metadata": {
        "id": "BNwJqKYZ9oij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "# Preprocess product descriptions and question-answer data\n",
        "product_data['text'] = product_data['summary'] + ' ' + product_data['reviewText'] + ' ' + product_data['question'] + ' ' + product_data['answer']\n",
        "product_data.dropna(subset=['text'], inplace=True)\n",
        "\n",
        "# Function to get top N similar products for a given product based on spaCy word vectors\n",
        "def get_similar_products_spacy(product_id, N=5):\n",
        "    idx = product_data[product_data['asin'] == product_id].index[0]\n",
        "    product_data['similarity_score'] = product_data['text_vector'].apply(lambda x: x.similarity(product_data['text_vector'][idx]))\n",
        "    similar_products = product_data.sort_values(by='similarity_score', ascending=False).head(N)\n",
        "    return similar_products\n"
      ],
      "metadata": {
        "id": "_VFo8hXE9wNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChatGPT-based Recommendations using OpenAI API"
      ],
      "metadata": {
        "id": "XJGK_Sz3-CMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatgpt_recommendations(prompt):\n",
        "    openai.api_key = \"YOUR_API_KEY\"  # Replace with your GPT-3 API key\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=150,\n",
        "        temperature=0.7,\n",
        "        n=10,  # Number of recommendations to generate\n",
        "        stop=[\"\\n\"]\n",
        "    )\n",
        "    recommendations = [r['choices'][0]['text'] for r in response['choices']]\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "X7scNYmE-DJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Advanced Recommender System combining collaborative filtering, NLP-based recommendations, and ChatGPT-based recommendations"
      ],
      "metadata": {
        "id": "wcuFLF_u9w3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def advanced_recommender(user_id, user_query):\n",
        "    # Collaborative Filtering Recommendations\n",
        "    user_products = merged_df[merged_df['reviewerID'] == user_id]['asin'].unique()\n",
        "    all_products = merged_df['asin'].unique()\n",
        "    products_to_predict = [product for product in all_products if product not in user_products]\n",
        "    user_predictions = [(user_id, product, collab_model.predict(user_id, product).est) for product in products_to_predict]\n",
        "    user_predictions.sort(key=lambda x: x[2], reverse=True)\n",
        "    top_collab_recommendations = [pid for uid, pid, score in user_predictions[:10]]\n",
        "\n",
        "    # NLP-based Recommendations\n",
        "    nlp_recommendations = nlp_based_recommendations(user_query)\n",
        "\n",
        "    # ChatGPT-based Recommendations\n",
        "    chatgpt_recommendations = chatgpt_recommendations(user_query)\n",
        "\n",
        "    # Weight the recommendations based on confidence level\n",
        "    weighted_recommendations = [(rec, 0.7) for rec in top_collab_recommendations] + [(rec, 0.8) for rec in nlp_recommendations] + [(rec, 1.0) for rec in chatgpt_recommendations]\n",
        "\n",
        "    # Sort the recommendations based on confidence level and get the top 10\n",
        "    weighted_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "    all_recommendations = [rec for rec, _ in weighted_recommendations[:10]]\n",
        "\n",
        "    return all_recommendations"
      ],
      "metadata": {
        "id": "KBAN4eX590_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#User Interaction with User Queries"
      ],
      "metadata": {
        "id": "jZDm6utx-Gi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enhanced_user_interaction():\n",
        "    print(\"Welcome to the Enhanced Product Recommender System!\")\n",
        "    user_id = input(\"Please enter your user ID: \")\n",
        "    user_query = input(\"Please enter your query: \")\n",
        "\n",
        "    recommended_products = advanced_recommender(user_id, user_query)\n",
        "\n",
        "    print(\"\\nRecommended Products:\")\n",
        "    for idx, pid in enumerate(recommended_products, 1):\n",
        "        product_name = product_data[product_data['asin'] == pid]['summary'].iloc[0]\n",
        "        print(f\"{idx}. Product ID: {pid}, Product Name: {product_name}\")"
      ],
      "metadata": {
        "id": "WJKUUeZo-Mux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation Metrics"
      ],
      "metadata": {
        "id": "3HIm_qsM-PsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def evaluate_recommender(predictions):\n",
        "        # Ground truth ratings for the test set\n",
        "        true_ratings = np.array([pred.r_ui for pred in predictions])\n",
        "\n",
        "        # Predicted ratings by the recommender system\n",
        "        predicted_ratings = np.array([pred.est for pred in predictions])\n",
        "\n",
        "        # Mean Average Precision (MAP)\n",
        "        map_score = average_precision_score(true_ratings > 3, predicted_ratings)\n",
        "\n",
        "        # Discounted Cumulative Gain (DCG)\n",
        "        dcg_score = dcg_score([true_ratings], [predicted_ratings])\n",
        "\n",
        "        # Recall\n",
        "        threshold = 3.5\n",
        "        predicted_labels = (predicted_ratings > threshold).astype(int)\n",
        "        true_labels = (true_ratings > threshold).astype(int)\n",
        "        recall = recall_score(true_labels, predicted_labels)\n",
        "\n",
        "        return map_score, dcg_score, recall\n",
        "\n",
        "    # Evaluate the recommender system\n",
        "    map_score, dcg_score, recall = evaluate_recommender(predictions)\n",
        "    print(f\"Mean Average Precision (MAP): {map_score:.4f}\")\n",
        "    print(f\"Discounted Cumulative Gain (DCG): {dcg_score:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_SSSzuHd-SnT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}